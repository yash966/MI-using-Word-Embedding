{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRlfRntWHn-8",
        "outputId": "bd14e019-a060-400f-b2bc-bc41fbc35736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy==1.19.5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the packages"
      ],
      "metadata": {
        "id": "e3IQnWfJoCIq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "fGt_onW449nN"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.models import Sequential\n",
        "import tqdm\n",
        "import sklearn.metrics\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.metrics import Recall, Precision\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import optimizers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "id": "GUd_goIMoGIY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "79FNzkltU8gr"
      },
      "outputs": [],
      "source": [
        "dtfrm = []\n",
        "\n",
        "data_spm = open('/content/spambase_csv.csv')\n",
        "reader = csv.reader(data_spm)\n",
        "next(reader, None)\n",
        "\n",
        "for row in reader:\n",
        "    dtfrm.append(row)\n",
        "data_spm.close()\n",
        "\n",
        "X = [x[:-1] for x in dtfrm]\n",
        "y = [x[-1] for x in dtfrm] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "_G_UD7_GBR6-"
      },
      "outputs": [],
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(X)\n",
        "\n",
        "X = t.texts_to_sequences(X)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X = pad_sequences(X, maxlen=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Y7bZqzCcQoui"
      },
      "outputs": [],
      "source": [
        "sq_lt = 100 \n",
        "emsize = 100  \n",
        "test_size = 0.25 \n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10 \n",
        "\n",
        "lblconv = {\"ham\": 0, \"spam\": 1}\n",
        "int2label = {0: \"ham\", 1: \"spam\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "WYy5N_Nc9XRM"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X = pad_sequences(X, maxlen=sq_lt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Ynau_FMbBEK3"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split and shuffle"
      ],
      "metadata": {
        "id": "r39XI9RZoPYV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7HjRhkABHSS",
        "outputId": "1f7b8750-1e63-4069-e6a8-5723c90e436f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainX.shape: (3450, 100)\n",
            "testX.shape: (1151, 100)\n",
            "trainY.shape: (3450, 2)\n",
            "testY.shape: (1151, 2)\n"
          ]
        }
      ],
      "source": [
        "test_size = 0.25\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(X, y, test_size=test_size, random_state=7)\n",
        "s\n",
        "print(\"trainX.shape:\", trainX.shape)\n",
        "print(\"testX.shape:\", testX.shape)\n",
        "print(\"trainY.shape:\", trainY.shape)\n",
        "print(\"testY.shape:\", testY.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "kkiZjifkMCs3"
      },
      "outputs": [],
      "source": [
        "def embd_vec(dim=100):\n",
        "  embd_indx = {}\n",
        "\n",
        "  with open(f\"/content/glove.6B.100d.txt\", encoding='utf8') as f:\n",
        "        for line in tqdm.tqdm(f, \"Reading GloVe\"):\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vectors = np.asarray(values[1:], dtype='float32')\n",
        "            embd_indx[word] = vectors\n",
        "\n",
        "  word_index = t.word_index\n",
        "\n",
        "  embd_mtx = np.zeros((len(word_index)+1, 100))\n",
        "  for word, i in word_index.items():\n",
        "    embedding_vector = embd_indx.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embd_mtx[i] = embedding_vector\n",
        "  return embd_mtx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTuoO_U6BJoV",
        "outputId": "2ab24ff2-0c0e-4471-8db0-96bf6d71790c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading GloVe: 400000it [00:19, 20369.82it/s]\n"
          ]
        }
      ],
      "source": [
        "embd_mtx = get_embedding_vectors()\n",
        "model = Sequential()\n",
        "model.add(Embedding(4513,\n",
        "              EMBEDDING_SIZE,\n",
        "              weights=[embd_mtx],\n",
        "              trainable=False,\n",
        "              input_length=SEQUENCE_LENGTH))\n",
        "\n",
        "model.add(LSTM(128, recurrent_dropout=0.2))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(2, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKhxrHybNPQH",
        "outputId": "3572e864-7eb4-4b46-81c9-bf5dc4cb6139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 100, 100)          451300    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 128)               117248    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 568,806\n",
            "Trainable params: 117,506\n",
            "Non-trainable params: 451,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Zk4ZbBEVN0LV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "JaE4S0xbN5pK"
      },
      "outputs": [],
      "source": [
        "optimum=optimizers.Adam(clipvalue=0.5)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUjH7J1kN8gj",
        "outputId": "72076da5-b375-4c23-8df4-da75aacf08e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.7603\n",
            "Epoch 1: val_loss improved from inf to 0.37760, saving model to results/spam_classifier_0.38.h5\n",
            "54/54 [==============================] - 31s 478ms/step - loss: 0.4916 - accuracy: 0.7603 - val_loss: 0.3776 - val_accuracy: 0.8271\n",
            "Epoch 2/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.8490\n",
            "Epoch 2: val_loss did not improve from 0.37760\n",
            "54/54 [==============================] - 20s 371ms/step - loss: 0.3567 - accuracy: 0.8490 - val_loss: 0.4402 - val_accuracy: 0.7976\n",
            "Epoch 3/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.8751\n",
            "Epoch 3: val_loss improved from 0.37760 to 0.31120, saving model to results/spam_classifier_0.31.h5\n",
            "54/54 [==============================] - 18s 321ms/step - loss: 0.3108 - accuracy: 0.8751 - val_loss: 0.3112 - val_accuracy: 0.8801\n",
            "Epoch 4/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.8757\n",
            "Epoch 4: val_loss did not improve from 0.31120\n",
            "54/54 [==============================] - 16s 294ms/step - loss: 0.2991 - accuracy: 0.8757 - val_loss: 0.3179 - val_accuracy: 0.8697\n",
            "Epoch 5/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.8870\n",
            "Epoch 5: val_loss improved from 0.31120 to 0.29725, saving model to results/spam_classifier_0.30.h5\n",
            "54/54 [==============================] - 16s 291ms/step - loss: 0.2904 - accuracy: 0.8870 - val_loss: 0.2972 - val_accuracy: 0.8740\n",
            "Epoch 6/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.8962\n",
            "Epoch 6: val_loss did not improve from 0.29725\n",
            "54/54 [==============================] - 17s 311ms/step - loss: 0.2691 - accuracy: 0.8962 - val_loss: 0.3328 - val_accuracy: 0.8662\n",
            "Epoch 7/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.8980\n",
            "Epoch 7: val_loss improved from 0.29725 to 0.28103, saving model to results/spam_classifier_0.28.h5\n",
            "54/54 [==============================] - 16s 292ms/step - loss: 0.2638 - accuracy: 0.8980 - val_loss: 0.2810 - val_accuracy: 0.8940\n",
            "Epoch 8/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.8965\n",
            "Epoch 8: val_loss improved from 0.28103 to 0.27619, saving model to results/spam_classifier_0.28.h5\n",
            "54/54 [==============================] - 16s 301ms/step - loss: 0.2639 - accuracy: 0.8965 - val_loss: 0.2762 - val_accuracy: 0.8897\n",
            "Epoch 9/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.8986\n",
            "Epoch 9: val_loss improved from 0.27619 to 0.26355, saving model to results/spam_classifier_0.26.h5\n",
            "54/54 [==============================] - 16s 293ms/step - loss: 0.2493 - accuracy: 0.8986 - val_loss: 0.2636 - val_accuracy: 0.8923\n",
            "Epoch 10/10\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.9061\n",
            "Epoch 10: val_loss did not improve from 0.26355\n",
            "54/54 [==============================] - 16s 302ms/step - loss: 0.2454 - accuracy: 0.9061 - val_loss: 0.3751 - val_accuracy: 0.8349\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ae0ee0bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "mdl_chpt = ModelCheckpoint(\"results/spam_classifier_{val_loss:.2f}.h5\", save_best_only=True,\n",
        "                                    verbose=1)\n",
        "\n",
        "tensorboard = TensorBoard(f\"logs/spam_classifier_{time.time()}\")\n",
        "\n",
        "model.fit(trainX, trainY, validation_data=(testX, testY),\n",
        "          batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "          callbacks=[tensorboard, mdl_chpt],\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6oz7tdLOACz",
        "outputId": "5767e4db-b7d0-49e4-8141-6c8997b3e41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 1s 34ms/step - loss: 0.3751 - accuracy: 0.8349\n",
            "[+] Accuracy: 83.49%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "output = model.evaluate(testX, testY)\n",
        "\n",
        "loss = output[0]\n",
        "accuracy = output[1]\n",
        "\n",
        "print(f\"[+] Accuracy: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "tiKJZBQUO8NY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Task2_AI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}